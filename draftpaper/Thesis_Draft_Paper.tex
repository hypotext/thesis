%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% writeLaTeX Example: Academic Paper Template
%
% Source: http://www.writelatex.com
% 
% Feel free to distribute this example, but please keep the referral
% to writelatex.com
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\synctex=1
\documentclass[twocolumn,showpacs,%
  nofootinbib,aps,superscriptaddress,%
  eqsecnum,prd,notitlepage,showkeys,10pt]{revtex4-1}

\usepackage{natbib}
% \usepackage[square,numbers]{natbib} % TODO
\bibliographystyle{unsrtnat}

% \usepackage{lstlangcoq} TODO

% displays all math in sans-serif font TODO  
\usepackage[cm]{sfmath}
  
\usepackage{graphicx}
\usepackage{verbatim} % for comments
\graphicspath{ {images/} }

\usepackage{listings}
\lstset{
basicstyle=\small\ttfamily,
%basicstyle=\ttfamily,
columns=flexible,
breaklines=true
}
%\lstset{language=Coq}

\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{hyperref}
\usepackage{enumitem}

\newenvironment{game}
{ \begin{itemize}[noitemsep,nolistsep] 
}
%    \setlength{\itemsep}{0pt}
  %     \setlength{\parskip}{0pt}
    % \setlength{\parsep}{0pt}     }
{ \end{itemize}                  } 

% \newcommand{name}[num]{definition}
\newcommand{\eqn}[1] {\begin{gather*}#1\end{gather*}}
\newcommand{\spc} {\textrm{ }}
\newcommand{\s} {\textrm{ }}
%\newcommand{\code}[1] {\begin{lstlisting}#1\end{lstlisting}}
\newcommand{\bv} {\begin{verbatim}}
\newcommand{\ev} {\end{verbatim}}
%\newcommand{\bl} {\begin{lstlisting}}
%\newcommand{\el} {\end{lstlisting}}
%\newcommand{\ct}[1]{}
\newcommand{\ct}[2]{\hspace{0in}#2}
\newcommand{\li} {\lstinline}
\newcommand{\kv} {$(K, V)$ }

\newcommand{\f}{\frac}
\newcommand{\cd}{\cdot}
\newcommand{\ld}{\ldots}
\newcommand{\xor}{\oplus}
\newcommand{\oh}{\f{1}{2}}
\newcommand{\adv}{\mathcal{A}}
\newcommand{\ged}{(\mathcal{G}, \mathcal{E}, \mathcal{D})}
\newcommand{\D}{\mathcal{D}}
\newcommand{\non}{\alpha(n)}
\newcommand{\mc}{\mathcal}
\newcommand{\ov}{\overline}
\newcommand{\dr}{\{0,1\}^n \rightarrow \{0,1\}^n}
\newcommand{\rar}{\rightarrow}
\newcommand{\bt}{\{0,1\}}
\newcommand{\samp}{\xleftarrow{R} \{0,1\}}
\newcommand{\lar}{\leftarrow}

\newtheorem{thm}{Theorem}
\newtheorem{dfn}[thm]{Definition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}{Lemma}[thm]

\begin{document}

\title{Formally verifying a pseudo-random number generator}
\author{Katherine Ye, advised by Prof. Andrew W. Appel}
\affiliation{Princeton University}
\author{and Prof. Matthew Green}
\affiliation{Johns Hopkins University}

\begin{abstract}
We have proved, with machine-checked proofs, that the pseudorandom output produced by HMAC-DRBG is indistinguishable from random by a computationally bounded adversary. We proved this about a high-level specification of HMAC-DRBG written in the probabilistic language provided by the Foundational Cryptography Framework (FCF), which is embedded in the Coq proof assistant. We also plan to prove that HMAC-DRBG is backtracking-resistant and prediction-resistant. After these proofs are done, we will prove equivalence between our high-level specification of HMAC-DRBG and a different specification used to prove its functional correctness of the mBED TLS C implementation of HMAC-DRBG. This will allow our proofs of cryptographic security properties to transfer to the C implementation of HMAC-DRBG.
\end{abstract}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Most modern cryptosystems rely on random numbers, which they use to generate secrets that need to be known to users and unknown and unpredictable to attackers. Reducing the entropy of a cryptosystem's pseudo-random number generator (PRNG) is an easy way to break the entire cryptosystem. The PRNG will generate output predictable to an attacker, allowing her to guess private keys, yet the bits may still “look” random. Plus, the rest of the cryptosystem will function normally, since PRNGs tend to be single self-contained components. These two factors make PRNGs very attractive targets to attackers.

The attack has indeed happened in practice (through due to a programming error and not malice), and with devastating consequences. Luciano Bello discovered that the random number generator in Debian OpenSSL, a widely-used cryptographic library, was predictable, allowing attackers to easily guess keys. Debian advised all users to regenerate keys, though some high-profile users didn't. For example, compromised SSH keys were used to access Spotify, Yandex, and gov.uk's public repositories on GitHub.

Despite the importance of PRNGs, surprisingly little work exists on proving them secure, either by proving on paper that certain widely-used PRNGs are secure, or by verifying with computer-checked proofs that implementations of these PRNGs satisfy their specifications.

%Our project aims to do both. We aim prove correctness and security of an OpenSSL implementations of  HMAC-DRBG. We will do this by proving that the implementation satisfies a functional specification (a high-level implementation in code) of the random number generator, which we trust satisfies its paper specification. Then we will prove that the functional specification guarantees the expected cryptographic properties, most notably that a computationally bounded attacker cannot distinguish generated bits from random bits. These properties will “flow” from the functional spec down to the compiled code via a verified compiler, CompCert. The entire verification will be machine-checked by Coq, a trusted proof assistant.

%This thesis attacks the cryptographic aspect of the problem. We hope to prove that PRNGs called CTR-DRBG and HMAC-DBG generate bits that are indistinguishable from random, that the PRGs are backtracking-resistant, that they eventually recover from compromises of internal state, and other important properties. We will write functional specifications of these PRGs in the environment of the Coq proof assistant, then prove that they possess the desired properties by using the Foundational Cryptography Framework in Coq.

%(@@@ revise last paragraphs)

% @ delete this section
%\section{Statement of main result}

We present the first machine-checked proof of a crucial cryptographic security property of a pseudo-random number generator. That is, we have written a precise specification of HMAC-DRBG's main functions in Coq, then we have proved that the probability that a non-adaptive probabilistic polynomial time adversary can distinguish HMAC-DRBG's output from uniformly-sampled random bits is negligible. We have also proved a concrete bound on the probability that the adversary can distinguish the two. 

%@ cite and add names
There exist only two prior proofs of security of HMAC-DRBG. The first, by Campagna (2006), is not peer-reviewed. The second, by Hirose (2008), was peer-reviewed, but its proof is lengthy and involved. Neither paper's proofs has been machine-checked or linked to an implementation of HMAC-DRBG.

After this, we plan to prove additional cryptographic properties of HMAC-DRBG, including backtracking resistance. No paper proofs exist for any of these additional properties. 

Additionally, we plan to connect our proof of security with an existing proof of correctness to create an end-to-end machine-checked proof chain of functional correctness and security of HMAC-DRBG, which has never been done before.

TODO: include precise theorem statement

\section{Problem background and related work}

Andrew Appel's group has done the most significant related work in the area. Appel (2015) presents a “full formal machine-checked verification of a C program: the OpenSSL implementation of SHA-256.” Beringer et al. (2015) build on this work to do the same for HMAC, adding a proof of security that relies on the security of SHA. We plan to use the same approach for CTR-DRBG and HMAC-DRBG.

In addition, there exist paper proofs of the security of CTR-DRBG and HMAC-DRBG (Campagna (2006), Hirose (2008)), though the former hasn't appeared in a peer-reviewed venue and the latter is very complicated.

In the area of checking game-based proofs of cryptographic security within a proof assistant, there are two main tools: EasyCrypt and its cousin CertiCrypt (neither of which is foundational), and the Foundational Cryptography Framework (Barthe (2011)).

In the general area of formalizing PRNGs, several crypto papers analyze the security of PRNGs and propose new security properties, e.g. Dodis et al. (2013) who propose the “robustness” property and show that the built-in Linux PRNG, /dev/random, is not robust.

There's not much prior work on formal verification of PRNGs in our style. Dorre and Klebanov (2015)  focus on verifying that a PRNG uses all its entropy. They perform this logic-based information flow verification using the KeY system for Java, which uses symbolic execution. This only defends against one particular attack (that of “squandering entropy”) and does not guarantee functional correctness or other security properties we may care about, such as indistinguishability from randomness and backtracking resistance.

Affeldt (2009) do include game-playing proofs of provable security in Coq. However, they focus on doing so directly on an assembly implementation of a PRNG, not on a high-level functional specification. They also verified their own assembly implementation, not a widely-used existing one. One advantage of this approach is that it avoids mismatches between the functional specification of the C code and the functional specification used for cryptographic proofs.

Our approach is unique because it provides an end-to-end and foundational verification that guarantees both correctness and security. Our stack consists of Coq, the Foundational Cryptography Framework, the Verified Software Toolchain (using separation logic), and CompCert (a verified C compiler). In addition, we verify an existing widely-used PRG implementation in C, making our approach more useful in practice. 

(TODO: fix these citations)

\section{HMAC-DRBG overview}
% **
A pseudorandom number generator is used to stretch a small amount of randomness into a large amount of pseudo-randomness, often for use in cryptosystems. HMAC-DRBG, formalized in NIST SP 800-90A, is one such pseudorandom number generator. It generates output by iterating HMAC, a keyed-hash message authentication function widely believed to be difficult to invert [cite] and that proven to be a pseudo-random function (PRF) given that HMAC's internal hash function is a PRF. % [mention key?]

The following section summarizes HMAC-DRBG's description in NIST SP 800-90A.

HMAC-DRBG possesses an internal state consisting of two pieces of administrative information, which are constant across calls, and two pieces of secret information, which are updated across calls.

The internal state consists of:

\begin{itemize}
\item Administrative information:
  \begin{itemize}
  \item The security strength of the PRG's instantiation. The $Instantiate$ function obtains the appropriate amount of entropy for that security strength.
  \item A prediction resistance flag that indicates whether this instantiation requires prediction resistance. Prediction resistance is explained in the next section.
  \end{itemize}

  \item The working state, which we often refer to as $(k,v)$.
  \begin{itemize}
  \item The secret key $k$ of length $c$ for the internal PRF, which is HMAC. It is updated at least once each time the PRG generates pseudorandom bits by calling the $Generate$ function.
  \item An internal value $v$ of length $c$, which is updated each time the PRG generates another block of pseudorandom bits of length $c$.
  \end{itemize}

\end{itemize}

HMAC-DRBG consists of four functions, $Update$, $Instantiate$, $Reseed$, and $Generate$, and another function we don't model called $getEntropy$. For simplicity, we omit the $additional\_input$ and $personalization\_string$ parameters from $Instantiate$. Our proof of security does not include them. Refer to NIST SP 800-90A for the full pseudocode. 

Let $f$ denote HMAC and $f_k$ denote HMAC partially applied with the key $k$. Let $||$ denote concatenation. Here we will not use mutable variables as NIST does, but write our code in a more functional style, which will make it more readable.\\

$Update$ refreshes $(k, v)$, optionally using some $data$, which can be fresh entropy for prediction resistance.\\

$\textbf{Update}(data, k, v) := $
\begin{game}
\item[] $k_1 \lar f_k(v || 0x00 || data)$
\item[] $v_1 \lar f_{k_1}(v)$
\item[] if $(provided\_data = nil)$, $ret (k_1, v_1)$
\item[] $k_2 \lar f_{k_1}(v_1 || 0x01 || data)$
\item[] $v_2 \lar f_{k_2}(v_1)$
\item[] $ret \s (k_2, v_2)$\\
\end{game}

$Instantiate$ initializes $(K,V)$ and $reseed\_counter$.  \\

$\textbf{Instantiate}(entropy, nonce) := $
\begin{game}
\item[] $seed \lar entropy || nonce$
\item[] $k \lar 0x00 \ldots 00$
\item[] $v \lar 0x01 \ldots 01$
\item[] $(k_1, v_1) \lar Update(seed, k, v)$
\item[] $reseed\_counter \lar 1$
\item[] $ret \s (k_1, v_1, reseed\_counter)$\\
\end{game}

$Reseed$ could be called for two reasons. First, $reseed\_counter$ could have exceeded $reseed\_interval$. This is rare, since $reseed\_interval$ is set to high values in practice; its maximum value is $2^{48}$, meaning it would naturally reseed once every couple of million years. (Indeed, in practice, one does not want a PRG to reseed often. This would give an attacker more opportunities to compromise the entropy source.) More commonly, $Reseed$ is called when a PRG's state could have be compromised, and requires fresh entropy to be mixed in.\\

$\textbf{Reseed}(k, v, entropy) := $
\begin{game}
\item[] $(k_1, v_1) \lar Update(seed, k, v)$
\item[] $reseed\_counter \lar 1$
\item[] $ret \s (k,v, reseed\_counter)$ \\
\end{game}

$Generate$ generates $n$ blocks of pseudorandom bits.
% $Gen\_loop$ is the internal bit-generating loop of $Generate$, rephrased in a functional and recursive manner from the original imperative $while$ loop. $c$ is the input/output size of $f_k$ (HMAC). \\

% $\textbf{Gen\_loop(n, k, v)} :=$
% \begin{game}
% \item[] if $n = 0$ then return $nil$ (the empty list)
% \item[] else return $f_k(v) || H(n-1, k, f_k(v)).$\\
% \end{game}

$\textbf{Generate(k, v, n)} := $
\begin{game}
\item[] if $reseed\_counter > reseed\_interval$, 
  \begin{game}
  \item[] $ret$ ``reseed required''
  \end{game}
% \item[] $bits \lar Gen\_loop(\lceil \f{n}{c} \rceil, k,v)$
\item[] $temp_0 \lar nil$
\item[] $v_0 \lar v$
\item[] while $len(temp_i) < n$
  \begin{game}
    \item[] $v_{i+1} \lar f_k(v_i)$
    \item[] $temp_{i+1} \lar temp_i || v_{i+1}$
  \end{game}
\item[] (say the loop above ran $j$ times)
\item[] $returned\_bits \lar$ leftmost $n$ of $temp_j$
\item[] $(k_1, v_{j+1}) \lar Update(k, v_j)$
\item[] $reseed\_counter_1 \lar reseed\_counter + 1$
\item[] $ret \s (bits, k_1, v_{j+1}, reseed\_counter_1)$\\
\end{game}

From the user's point of view, only the $Instantiate$ and $Generate$ functions are visible. The state is, of course, hidden. Typical usage would be a call to $Instantiate$, followed by any number of calls to $Generate$ some number of pseudorandom bits. $Generate$ automatically calls $Update$ every time it is called, and $Generate$ may call $Reseed$.

We discuss our proof of security for a simplified PRG, consisting of only one call to the internal loop in $Generate$, in section REFERENCE. We discuss our proof of security for a simplified version of HMAC-DRBG in section REFERENCE.

\subsection{Security properties}

The most important property for a PRG is that its output is indistinguishable from ideal randomness. This definition will be formally stated in the proof in section REFERENCE.
% If an attacker can predict, then it can...

A good PRG ought to also possess \emph{backtracking resistance} and \emph{prediction resistance}.

If a PRG is backtracking resistant, then if the working state of the PRG is compromised at some time, any of its (previously unseen) output from before that time remains indistinguishable from ideal randomness.

This definition will be formally stated in the proof in section REFERENCE.

Prediction resistance is the complementary property. If a PRG is prediction resistant, then if the working state of the PRG is compromised at some time, after a certain recovery or reseeding interval, it is again indistinguishable from ideal randomness for any time afterward.

% cite entropy extractor stuff

We do not prove that HMAC-DRBG is prediction resistant. This is because the definition is slippery, and because it is difficult to prove.

\section{Proofs}

In this section we will write proofs as a conventional cryptographer would. We prove three things: indistinguishability for a simple PRG constructed from a PRF, indistinguishability for a real-world PRG constructed from a PRF, and backtracking resistance for the same PRG.

For any game $G$ that returns a boolean, let $\Pr[G]$ denote the probability that $G$ returns true. 

\subsection{Indistinguishability proof for one call}
% TODO mention EasyCrypt tutorial -- it's on this level
% hardness of PRF

Adam Petcher proved the security of the core loop construction of \li|HMAC_DRBG|. We summarize his proofs here.

First, take any family of PRFs $$F_c = \{f_k : \{0,1\}^c \rightarrow \{0,1\}^c\}_{k \in \{0,1\}^c}.$$

Construct a PRG $$H : (n : \mathbb{N}) \rightarrow (k : \{0,1\}^c) \rightarrow (v : \{0,1\}^c) \rightarrow (bits : \{0,1\}^{cn})$$

It takes an input seed and applies the PRF to it, then uses the output as one block of pseudorandom bits and as the next input seed to the PRG. $n$ is the number of blocks desired, $k$ is the key for the PRF, and $c$ (the input/output size of the PRF) is the security parameter. \\

$H(n, k, v) :=$
\begin{game}
\item[] if $n = 0$ then return $nil$ (the empty list)
\item[] else return $f_k(v) || H(n-1, k, f_k(v)).$\\
\end{game}

For example, $H(0,k, v_0) = nil$, and $$H(3, k, v_0) = f_k(v_0) || f_k(f_k(v_0)) || f_k(f_k(f_k(v_0))).$$

The user (or adversary) can request any number of blocks $n$ polynomial in the security parameter $c$, and the length of the seed is $c$. Thus, the stretch of $H$ is $l(n, c) = cn$. When we use $H$, we pass in $k \xleftarrow{R} \bt^c$.

We want to prove that the bits generated by $H$ are pseudorandom. 

% TODO what is "polynomial number of blocks"?
% the probability is over the randomness of the key or something else?

\begin{dfn}For all non-uniform, non-adaptive probabilistic polynomial time distinguishers $D$, number of blocks $n$ that is polynomial in $c$, there exists a negligible function such that
$$| \Pr [ D (H (n, k, U_c) = 1] - \Pr [ D(U_{cn}) = 1] | \leq neg(c,n),$$

where $U_c \xleftarrow{R} \{0,1\}^c$ ($U_c$ is sampled uniformly at random from $\{0,1\}^c$), $U_{cn} \xleftarrow{R} \{0,1\}^{cn}$, and $k \xleftarrow{R} \{0,1\}^c$ ($k$ is the key for the PRF).\end{dfn}

%$D$ is nonadaptive because it has to pick the number of blocks ahead of time. One can imagine a pathological PRG that chooses a random number of blocks after which to output its seed, and outputs that number of blocks as its first block (which is still random). An adaptive adversary could then distinguish with probability $\f{1}{2}$, whereas a non-adaptive adversary would have a negligible probability of doing so. % TODO footnote on difficulty?

The probability that the distinguisher returns $1$ when given the PRG's output, $\Pr[D(H(n, k,  U_c) = 1]$, is the same as the probability that the result of this real-world game is $1$. \\

$\textbf{G\_real} := $
\begin{game}
\item[] $n \leftarrow D$ (the distinguisher picks a number of blocks)
\item[] $k \xleftarrow{R} \{0,1\}^c$
\item[] $v \xleftarrow{R} \{0,1\}^c$
\item[] $bits \leftarrow H(n,k,v)$
\item[] $ret \s D(bits)$ \\
\end{game}

That is, $\Pr[D(H(n, k, U_c) = 1)] = \Pr[G\_real]$

The probability that the distinguisher returns $1$ when given a uniformly randomly sampled bit string of length $cn$ is the same as the probability that the result of this ideal-world game is $1$. Let $generate\_bitvectors \s n$ generate a list of $n$ uniformly randomly sampled bitvectors of length $c$ each.\\

$\textbf{G\_ideal} := $
\begin{game}
\item[] $n \leftarrow D$ (the distinguisher picks a number of blocks)
\item[] $bits \leftarrow generate\_bitvectors \s n$
\item[] $ret \s D(bits)$ \\
\end{game}

That is, $\Pr[D(U_{nx}) = 1)] = \Pr[G\_ideal]$.

So, to bound the probability of distinguishing, $$| \Pr [ D (H (x, U_n) = 1] - \Pr [ D(U_{nx}) = 1] |,$$ we bound the distance between the two games, $$| \Pr[G\_real] - \Pr[G\_ideal]|.$$ 

To bound this distance, we introduce an intermediate game, $G\_intermediate$. First, in the PRG, we replace the PRF with a random function $$R_c = \{ r : \{0,1\}^* \rightarrow \{0,1\}^c\}.$$ 

$H\_{rf}(n, v) :=$
\begin{game}
\item[] if $n = 0$ then return $nil$
\item[] else return $r(v) || H(n-1, r(v)).$\\
\end{game}

Next, we define $G\_intermediate$ with the same structure as $G\_real$, but using $H\_{rf}$ (the PRG using the random function) instead of $H$.\\

$\textbf{G\_intermediate} := $
\begin{game}
\item[] $n \leftarrow D$ (the distinguisher picks a number of blocks)
\item[] $v \xleftarrow{R} \{0,1\}^c$
\item[] $bits \leftarrow H\_{rf}(n,v)$
\item[] $ret \s D(bits)$ \\
\end{game}

Then we calculate the overall bound using this intermediate game. We first bound the difference between the real and the intermediate game, then between the intermediate and the ideal game.

\begin{thm} \begin{gather*}| \Pr[G\_real] - \Pr[G\_ideal]| = \\
|\Pr[G\_real] - \Pr[G\_intermediate]| \\
-  |\Pr[G\_intermediate] - \Pr[G\_ideal]|. \end{gather*} \end{thm}
\begin{proof} By the triangle inequality. \end{proof}

\begin{thm} \begin{gather*}|\Pr[G\_real] - \Pr[G\_intermediate]| \leq PRF\_Advantage.\end{gather*} \end{thm}
\begin{proof} 
We are not really doing math here; this follows by definition.

% PRF family, RF family?
$PRF\_Advantage$ is the maximum probability that any non-uniform probabilistic polynomial-time distinguisher $D_p$ can distinguish between a PRF (with input/output length $c$) and a random function (abbreviated RF from now on). It is given oracle access to one of them, which it can query a number of times polynomial in the security parameter $c$, and must output a guess.
$$| \Pr[ D_p^{f_k(\cdot)}(1^c) = 1] - \Pr[ D_p^{r(\cdot)}(1^c)=1 ] | \leq PRF\_Advantage$$

We can define it equivalently in terms of the distance between games, as discussed above.
$$| \Pr[ G\_Adv\_PRF] - \Pr[G\_Adv\_RF] | \leq PRF\_Advantage.$$

where the games are as follows:\\

$\textbf{G\_Adv\_PRF} := $
\begin{game}
\item[] $k \xleftarrow{R} \bt^c$
\item[] $b \leftarrow D_p^{f_k(\cdot)}$ 
\item[] $ret \s b$ \\
\end{game}

$\textbf{G\_Adv\_RF} := $
\begin{game}
\item[] $b \leftarrow D_p^{r(\cdot)}$ 
\item[] $ret \s b$ \\
\end{game}

Since we are doing proofs of concrete security, we must use this definition of the difference between a PRF and a RF. If we were proving asymptotic security, we would reduce the security of the PRG to the security of the PRF (which we do here) by showing that given a non-uniform PPT adversary against the PRG, we could construct a non-uniform PPT adversary against the PRF. But this does not yield a concrete bound.

Then we rewrite our existing games to fit the form of some adversary being given a particular oracle.\\

$\textbf{G\_real\_2} := $
\begin{game}
\item[] $k \xleftarrow{R} \bt^c$
\item[] $b \leftarrow PRF\_A^{f_k(\cdot)}$ 
\item[] $ret \s b$ \\
\end{game}

$\textbf{G\_intermediate\_2} := $
\begin{game}
\item[] $b \leftarrow PRF\_A^{r(\cdot)}$ 
\item[] $ret \s b$ \\
\end{game}

where $PRF\_A$, given either the PRF oracle or the RF oracle, simply generates the pseudorandom bits using the oracle and calls the existing PRG adversary on them. Note that $PRF\_A$ no longer samples the key for the PRF. \\

$\textbf{PRF\_A o} := $
\begin{game}
\item[] $n \leftarrow D$
\item[] $v \xleftarrow{R} \bt^c$
\item[] $bits \leftarrow H\_oc(o,n, v)$ 
\item[] $ret \s D(bits)$ \\
\end{game}

and $H\_oc$ is a modified version of the PRG that takes an oracle and queries it, in place of using the PRF.\\

$H\_{oc}(o, n, v) :=$
\begin{game}
\item[] if $n = 0$ then return $nil$
\item[] else return $o.query(v) || H(o, n-1, o.query(v)).$
\end{game}

\begin{lem} \begin{gather*}|\Pr[G\_real\_2] - \Pr[G\_intermediate\_2]| \leq PRF\_Advantage.\end{gather*} \end{lem}
\begin{proof} By the definition of $PRF\_Advantage$, with \\ $D_p := PRF\_A$. \end{proof}

And our two rewrites don't change the probability that the adversary returns $1$ in a particular game.

\begin{lem} $\Pr[G\_real] = \Pr[G\_real\_2].$ \end{lem}
\begin{proof} By substitution and program equivalence. \end{proof}

\begin{lem}\label{intermediate2} $\Pr[G\_intermediate] = \Pr[G\_intermediate\_2].$ \end{lem}
\begin{proof} By substitution and program equivalence.  \end{proof}

Thus, the theorem follows:
$$|\Pr[G\_real] - \Pr[G\_intermediate]| \leq PRF\_Advantage.$$ \end{proof}

Next, we bound the difference between the intermediate and the ideal-world game. This requires making a combinatorial argument.

\begin{thm} $| \Pr[G\_intermediate] - \Pr[G\_ideal]| \leq \f{n^2}{2^c}. $ \end{thm}
\begin{proof} 

We use Bellare's \emph{fundamental lemma of game-playing} to bound the distance between these two games.

If two games are \emph{identical until bad}, they are "syntactically identical except for statements that follow the setting of a flag bad to true" (Bellare (2004)). 

\begin{lem}(Fundamental lemma of game-playing) Let G and H be identical-until-bad games and
let A be an adversary. Then 
$$|\Pr[G^A = 1] - \Pr[H^A] = 1]| \leq Pr[H^A \s sets \s bad].$$ \end{lem} 
\begin{proof} See Bellare (2004). \end{proof}

Intuitively, the "bad event" in both $G\_intermediate$ and $G\_ideal$ is that there are duplicates in the inputs to the random function used in the former game. If there are no duplicates, then the random function behaves exactly like uniformly sampling random bits. If there are duplicates, then the random function becomes deterministic and starts to cyclically repeat outputs. Thus, we manipulate both games to expose this bad event.

Instead of using $G\_intermediate$, we modify $G\_intermediate\_2$, which we had proven equivalent (via program equivalence) to $G\_intermediate$ in Lemma \ref{intermediate2}. We replace the random function oracle with a random function oracle $rf$ that keeps track of all (input, output) pairs, including duplicate inputs. \\

$\textbf{G\_intermediate\_3} := $
\begin{game}
\item[] $b \leftarrow PRF\_A^{rf(\cdot)}$ 
\item[] $ret \s b.$ \\
\end{game}

Then we expose the bad event as the second element of the output. $PRF\_A$ now outputs the state of the oracle after many calls, though $PRF\_A$ itself does not have access to the state. \\

$\textbf{G\_intermediate\_4} := $
\begin{game}
\item[] $(b, state) \leftarrow PRF\_A^{rf(\cdot)}$ 
\item[] $ret \s (b, hasDups(inputsOf(state))).$ \\
\end{game}

In each of the three games, the probability that the adversary returns a guess of $true$ is the same.

Since some games will now return 2-tuples of booleans instead of single booleans, for such games $G$, we define $\Pr_1[G]$ to be the probability that the first value of the tuple is true and $\Pr_2[G]$ analogously.

\begin{lem} \begin{gather*}\Pr[G\_intermediate\_2] = \Pr[G\_intermediate\_3] \\ 
= \Pr_1[G\_intermediate\_4].\end{gather*} \end{lem}
\begin{proof}Adding state and duplicate tracking to the oracle does not change its outputs. Outputting whether the bad event happened does not change the adversary's guess. \end{proof}

We similarly rewrite $G\_ideal$ in the form of $G\_intermediate\_2$. We create an oracle $rb$ that, on any input, returns a uniformly sampled bitvector, and records the (input, output) pair in its state. Then we rephrase $G\_ideal$ in terms of $PRF\_A$ using $rb$.\\

$\textbf{G\_ideal\_2} := $
\begin{game}
\item[] $b \leftarrow PRF\_A^{rb(\cdot)}$ 
\item[] $ret \s b$ \\
\end{game}

Then we similarly expose the bad event.\\

$\textbf{G\_ideal\_3} := $
\begin{game}
\item[] $(b, state) \leftarrow PRF\_A^{rb(\cdot)}$ 
\item[] $ret \s (b, hasDups(inputsOf(state)))$ \\
\end{game}

In each of the three games, the probability that the adversary returns a guess of $true$ is the same.

\begin{lem}$$\Pr[G\_ideal] = \Pr[G\_ideal\_2] = \Pr_1[G\_ideal\_3].$$\end{lem}
\begin{proof}By unfolding the definition of $PRF\_A$ and program equivalence. (In both $G\_ideal$ and $G\_ideal\_2$, we generate a list of pseudorandom bits by uniformly randomly sampling a bitvector $n$ times.) Also, adding state and duplicate tracking to the oracle does not change its outputs, and outputting whether the bad event happened does not change the adversary's guess. \end{proof}

The two games, with the same bad event exposed, are identical until bad. Bellare's "syntactically identical except for the bad event" definition is too vague to use, so we assert that these games are identical until bad by a definition formalized by Petcher (2015):

\begin{enumerate}
\item The probability of the bad event is the same in both games. 
\item If the bad event does not happen, the distribution of the outputs is the same. 
\end{enumerate}

\begin{lem}$G\_intermediate\_4$ and $G\_ideal\_3$ are identical until bad.\end{lem}
\begin{proof} The random function behaves like uniformly sampling a bitvector, until one of its outputs happens to be one of its previous inputs. \end{proof}

Thus, we can apply the fundamental lemma of game-playing, which implies
\begin{gather*}
|\Pr_1[G\_intermediate\_4] - \Pr_1[G\_ideal\_3]| \leq \\ 
\Pr[G\_ideal\_3 \s sets \s bad] = \Pr_2[G\_ideal\_3].
\end{gather*}
This is convenient, because now we can just work with a single game, which allows us to apply our game-equivalence techniques. Now we only need to bound $\Pr_2[G\_ideal\_3]$. Since we only care about its second return value, we can discard the adversary's guess.\\

$\textbf{G\_ideal\_3B} := $
\begin{game}
\item[] $(b, state) \leftarrow PRF\_A^{rb(\cdot)}$ 
\item[] $ret \s hasDups(inputsOf(state))$ 
\end{game}

\begin{lem}$\Pr_2[G\_ideal\_3] = \Pr[G\_ideal\_3B].$\end{lem}
\begin{proof}The first return value is irrelevant.\end{proof}

$G\_ideal\_3B$ is unnecessarily complicated. We wrote it in the form of $PRF\_A$ in order to get it in the same form as $G\_intermediate\_4$ and prove that they were identical until bad. Now we return to the simpler form, which is essentially the original $G\_ideal$.\\

$\textbf{G\_ideal\_4} := $
\begin{game}
\item[] $n \leftarrow D$
\item[] $bits \leftarrow generate\_bitvectors \s n$
\item[] $ret \s (hasDups(bits))$ 
\end{game}

\begin{lem}$\Pr[G\_ideal\_3B] = \Pr[G\_ideal\_4]$.\end{lem}
\begin{proof}
By inlining $PRF\_A$, it becomes clear that the probability of $G\_ideal\_3B$ is the same as generating a list of $n$ uniformly-sampled bitvectors of length $c$ and returning whether there is a duplicate in that list. We can ignore the guess of the distinguisher $D$. %\ref{aaa}

To be more precise, $inputsOf(state))$ in $G\_ideal\_3B$ is a list of $n-1$ such bitvectors (inputs) with a randomly-sampled seed $v$ at the beginning, which is the first input.
\end{proof}

Thus, we need only upper-bound the probability that there is a duplicate in a list of $n$ uniformly-sampled bitvectors of length $c$. This is the probability that the bad event happens.

\begin{lem}$$\Pr[G\_ideal\_4] \leq \f{n^2}{2^c}$$\end{lem}
\begin{proof} There are $n \choose 2$ $= \f{n(n-1)}{2}$ pairs of bitvectors in the list, and the probability that there is a collision in a pair is $\f{1}{2^c}$. By the union bound, the probability that there is no collision is $\f{n(n-1)}{2} \cdot \f{1}{2^c} \leq \f{n^2}{2^c}.$ \end{proof}

This completes our bound on the difference between $G\_intermediate$ and $G\_ideal$.
\end{proof}

This bound on the probability of the bad event yields our final result:

\begin{thm}The distance between the two games is $$| \Pr[G\_real] - \Pr[G\_ideal]| \leq PRF\_Advantage + \f{n^2}{2^c}.$$ \end{thm}
% TODO name theorems
\begin{proof} By the triangle inequality, combined with theorems 3 and 4.\end{proof}

Thus, $H$ is a secure PRG. Moreover, since we did our proof in the concrete security model, we have a better idea of how secure it is (modulo the black box of $PRF\_Advantage$) than if we had proven its asymptotic security.

% TODO: remove this break (here for legibility)
\break

\subsection{Indistinguishability proof for multiple calls with state updating}
% ^^
\subsubsection{HMAC-DRBG}
TODO

\subsubsection{Setup}
To prove indistinguishability for HMAC-DRBG, we must extend the proof for $H$.

As summarized in section REFERENCE, the HMAC-DRBG functions are Instantiate, Generate, Update, Reseed. The state is a 3-tuple of (K, V, number of calls).

% TODO here
We model it as Instantiate, then Generate+Update as GenUpdate. (code for these)

The user (adversary) can make a polynomial number of calls to GenUpdate, requesting a polynomial number of blocks 

% oh -- generic list?

$\textbf{Instantiate} := $
\begin{game}
  \item[] $k \samp^m$
  \item[] $v \samp^c$ \\
\end{game}

Again we take $H$:

$H(n, k, v) :=$
\begin{game}
\item[] if $n = 0$ then return $nil$ (the empty list)
\item[] else return $f_k(v) || H(n-1, k, f_k(v)).$\\
\end{game}

For example, $H(0,k, v_0) = nil$, and $$H(3, k, v_0) = f_k(v_0) || f_k(f_k(v_0)) || f_k(f_k(f_k(v_0))).$$

And construct a PRG for multiple calls as such:
% !!

We combined the $Generate$ and $Update$ functions into one program, since they're always called together.

\begin{lstlisting}
Definition GenUpdate_original (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  [bits, v'] <-2 Gen_loop k v n;
  k' <- f k (to_list v' ++ zeroes);
  v'' <- f k' (to_list v');
  ret (bits, (k', v'')).
\end{lstlisting}

$\textbf{G\_real} := $
\begin{game}
\item[] $l \leftarrow D$ (the distinguisher outputs a list of TODO) 
\item[] $(k,v) \leftarrow Instantiate$
\item[] $bits \leftarrow GenUpdate(k,v,l)$
\item[] $ret \s D(bits)$ \\
\end{game}

$\textbf{G\_ideal} := $
\begin{game}
\item[] $l \leftarrow D$ (the distinguisher outputs a list of TODO) 
\item[] $bits \leftarrow GenRand(l)$
\item[] $ret \s D(bits)$ \\
\end{game}

The adversary, an abstract probabilistic polynomial time algorithm. It takes a list of blocks and returns a guess.

\begin{lstlisting}
(* Non-adaptive adversary. *)
Variable A : list (list (Bvector eta)) -> Comp bool.
Hypothesis A_wf: forall ls, well_formed_comp (A ls).
\end{lstlisting}

\subsubsection{Extending prior work}

We extend his work to deal with the following complications in the full HMAC-DRBG and model real-world usage.

\begin{itemize}
\item Additional functions: $Instantiate$, $Generate$, and $Update$.
\item Multiple calls to $Generate$ and $Update$.
\item We need to now consider whether the adversary is adaptive or non-adaptive.
\item The $V$ is updated after each call.
\item The $K$ is updated after each call, so the PRF is re-keyed.
%\item Instantiate
\end{itemize}

\subsubsection{Proof}
Dealing with key/v updating ?

Updating the v immediately after re-keying the PRF, in the same oracle call, is hard to reason about. This is because at the beginning of each call, by the hybrid argument, we can assume that the \kv have been randomly sampled. Now we have to replace the key with a random key to reason about updating the v. The solution is simple: we move each v-update to the beginning of the next call and prove that the new sequence of programs is indistinguishable to the adversary. (TODO explain this with pictures)

\begin{lstlisting}
(* [GenUpdate_original, GenUpdate_original, ...] = [GenUpdate_noV, GenUpdate, Genupdate, ...] *)
  (* use this for the first call *)
Definition GenUpdate_noV (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  [bits, v'] <-2 Gen_loop k v n;
  k' <- f k (to_list v' ++ zeroes);
  ret (bits, (k', v')).

Definition GenUpdate (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  v' <- f k (to_list v);
  [bits, v''] <-2 Gen_loop k v' n;
  k' <- f k (to_list v'' ++ zeroes);
  ret (bits, (k', v'')).
\end{lstlisting}

Relation to Adam's proof: we reduce it to his proof in the cases of
\begin{itemize}
\item identical until bad on the two oracle computations
\item probability of the bad event
\end{itemize}

% TODO: TeX all the games / functions / hybrids

Concrete bound

Hybrid argument

My hybrids (intermediate games)

$Gi\_rf$
$PRF\_A$

The PRF adversary. It uses the existing adversary so we can go from PRF to RF, which is much easier to reason about. (TODO: explained already below) Game $i$ here is more complicated because we can pass in any oracle to use on only the $i$th call, instead of the the hardcoding in game $i$ above. (TODO: talk about motivation for this)

\begin{lstlisting}
Definition PRF_Adversary (i : nat) : OracleComp Blist (Bvector eta) bool :=
  bits <--$ oracleCompMap_outer _ _ (Oi_oc' i) maxCallsAndBlocks;
  $ A bits.

(* ith game: use RF oracle *)
Definition Gi_rf (i : nat) : Comp bool :=
  [b, _] <-$2 PRF_Adversary i _ _ (randomFunc ({0,1}^eta) eqdbl) nil;
  ret b.
\end{lstlisting}

New oracles:
$Oi\_prg$
$Oi\_oc$

Sone words on dealing with the hybrids formally

New reductions/games (PRF, random function)

Direction of proof we COULD have taken

\subsection{Proof of backtracking resistance}

Formal def of backtracking resistance and adversary

Reductions/games re-using the previous one

\section{Foundational Cryptography Framework summary}

TODO: cover the following topics:

\begin{enumerate}
\item Shallowly-embedded into Coq
\item Game-based crypto proofs
\item Comp monad (probabilistic computations)
\item Relating pairs of games using probabilistic relational Hoare logic (postconditions, $comp\_spec$)
\item Oracles, hidden state, and oracle computations (OracleComp)
\item Modeling the adversary as any abstract probabilistic polynomial time algorithm
\item Writing games
\item FCF example
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Formal proof outline}

\subsection{Starting HMAC-DRBG definitions}

% TODO: I copy and pasted some of this into the paper proof section
The core inner loop of HMAC-DRBG that generates pseudorandom blocks. (TODO: compare and contrast each definition with the corresponding NIST pseudocode)

\begin{lstlisting}
(* save the last v and output it as part of the state *)
Fixpoint Gen_loop (k : Bvector eta) (v : Bvector eta) (n : nat)
  : list (Bvector eta) * Bvector eta :=
  match n with
  | O => (nil, v)
  | S n' =>
    let v' := f k (Vector.to_list v) in
    let (bits, v'') := Gen_loop k v' n' in
    (v' :: bits, v'')           
  end.
\end{lstlisting}

We combined the $Generate$ and $Update$ functions into one program, since they're always called together.

\begin{lstlisting}
Definition GenUpdate_original (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  [bits, v'] <-2 Gen_loop k v n;
  k' <- f k (to_list v' ++ zeroes);
  v'' <- f k' (to_list v');
  ret (bits, (k', v'')).
\end{lstlisting}

% @ where should this go?
\subsection{Prior work on abstract PRF-DRBG}

Adam Petcher did some prior work on proving the security of the core loop seen above, run once. His definition is similar to ours, but more abstract. Here $f$ is any $PRF$.

\begin{lstlisting}
  Fixpoint PRF_DRBG_f (v : D)(n : nat)(k : Key) :=
    match n with
        | O => nil
        | S n' => 
          r <- (f k v);
            r :: (PRF_DRBG_f (injD r) n' k)
    end.
\end{lstlisting}

We reuse his proof techniques to replace the PRF with a random function, then the random function with random bits. The first is bounded by \li|PRF_Advantage|, the second by the collision bound. (TODO: elaborate on this)

TODO: move the explanation of identical until bad (in $oracleCompMap$) here

\subsection{Proof of indistinguishability}

Here are the statement and the proof in Coq. Note that the proof relies on four main lemmas, which we discuss below.

\begin{lstlisting}
Theorem G1_G2_close :
  | Pr[G1_prg_original] - Pr[G2_prg] | <= 
  (numCalls / 1) * Gi_Gi_plus_1_bound.
Proof.
  rewrite G1_Gi_O_equal.
  rewrite G2_Gi_n_equal.
  (* inductive argument *)
  specialize (distance_le_prod_f 
  	(fun i => Pr[Gi_prg i]) 
	Gi_Gi_plus_1_close numCalls).
  intuition.
Qed.
\end{lstlisting}

TODO: discuss pseudorandom functions, random functions, uniformly sampling random bits.

TODO: Indistinguishability definition

\subsection{Hybrid argument}

\subsection{Main games}

TODO: talk about what a game is

Updating the v immediately after re-keying the PRF, in the same oracle call, is hard to reason about. This is because at the beginning of each call, by the hybrid argument, we can assume that the \kv have been randomly sampled. Now we have to replace the key with a random key to reason about updating the v. The solution is simple: we move each v-update to the beginning of the next call and prove that the new sequence of programs is indistinguishable to the adversary. (TODO explain this with pictures)

\begin{lstlisting}
(* [GenUpdate_original, GenUpdate_original, ...] = [GenUpdate_noV, GenUpdate, Genupdate, ...] *)
  (* use this for the first call *)
Definition GenUpdate_noV (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  [bits, v'] <-2 Gen_loop k v n;
  k' <- f k (to_list v' ++ zeroes);
  ret (bits, (k', v')).

Definition GenUpdate (state : KV) (n : nat) :
  Comp (list (Bvector eta) * KV) :=
  [k, v] <-2 state;
  v' <- f k (to_list v);
  [bits, v''] <-2 Gen_loop k v' n;
  k' <- f k (to_list v'' ++ zeroes);
  ret (bits, (k', v'')).
\end{lstlisting}

The adversary, an abstract probabilistic polynomial time algorithm. It takes a list of blocks and returns a guess.

\begin{lstlisting}
(* Non-adaptive adversary. *)
Variable A : list (list (Bvector eta)) -> Comp bool.
Hypothesis A_wf: forall ls, well_formed_comp (A ls).
\end{lstlisting}

The first game: modeling normal usage of the PRG with the PRF.

\begin{lstlisting}
(* blocks generated by GenLoop *)
Variable blocksPerCall : nat.      
(* number of calls to GenUpdate *) 
Variable numCalls : nat.        
Hypothesis H_numCalls : numCalls > 0. 

Definition maxCallsAndBlocks : list nat := replicate numCalls blocksPerCall.

(* only first call uses GenUpdate_noV; assumes numCalls > 0 *)
Definition G1_prg : Comp bool :=
  [k, v] <-$2 Instantiate;
  [head_bits, state'] <-$2 GenUpdate_noV (k, v) blocksPerCall;
  (* call the oracle numCalls times, each time requesting blocksPerCall blocks *)
  [tail_bits, _] <-$2 oracleMap _ _ GenUpdate state' (tail maxCallsAndBlocks);
  A (head_bits :: tail_bits).
\end{lstlisting}

The end game: everything returned is a uniformly sampled random bit vector.

\begin{lstlisting}
(* simpler version of GenUpdate only requires compMap. prove the two games equivalent *)
Definition G2_prg : Comp bool :=
  [k, v] <-$2 Instantiate;
  bits <-$ compMap _ GenUpdate_rb maxCallsAndBlocks;
  A bits.
\end{lstlisting}

Hybrid games. 
TODO: define notation, talk about why hybrid and why in this order, talk about oracles

Game $i$ uses RBs for all calls less than $i$ and PRF for all calls greater than or equal to $i$. Call numbering starts at $0$. It passes $i$ to oracle $i$, which chooses the appropriate oracle to use.

\begin{lstlisting}

(* oracle i *)
(* number of calls: first call is 0, last call is (numCalls - 1) for numCalls calls total
G0: PRF PRF PRF
G1: RB  PRF PRF
G2: RB  RB  PRF
G3: RB  RB  RB 
there should be (S numCalls) games, so games are numbered from 0 through numCalls *)
Definition Oi_prg (i : nat) (sn : nat * KV) (n : nat)
  : Comp (list (Bvector eta) * (nat * KV)) :=
  [callsSoFar, state] <-2 sn;
  let GenUpdate_choose := if lt_dec callsSoFar i (* callsSoFar < i *)
                          then GenUpdate_rb_intermediate
                          (* first call does not update v, to make proving equiv. easier*)
                          else if beq_nat callsSoFar O then GenUpdate_noV
                               else GenUpdate in
  (* note: have to use intermediate, not final GenUpdate_rb here *)
  [bits, state'] <-$2 GenUpdate_choose state n;
  ret (bits, (S callsSoFar, state')).

(* game i (Gi 0 = G1 and Gi q = G2) *)
Definition Gi_prg (i : nat) : Comp bool :=
  [k, v] <-$2 Instantiate;
  [bits, _] <-$2 oracleMap _ _ (Oi_prg i) (O, (k, v)) maxCallsAndBlocks;
  A bits.
\end{lstlisting}  

The PRF adversary. It uses the existing adversary so we can go from PRF to RF, which is much easier to reason about. (TODO: explained already below) Game $i$ here is more complicated because we can pass in any oracle to use on only the $i$th call, instead of the the hardcoding in game $i$ above. (TODO: talk about motivation for this)

\begin{lstlisting}
Definition PRF_Adversary (i : nat) : OracleComp Blist (Bvector eta) bool :=
  bits <--$ oracleCompMap_outer _ _ (Oi_oc' i) maxCallsAndBlocks;
  $ A bits.

(* ith game: use RF oracle *)
Definition Gi_rf (i : nat) : Comp bool :=
  [b, _] <-$2 PRF_Adversary i _ _ (randomFunc ({0,1}^eta) eqdbl) nil;
  ret b.
\end{lstlisting}

Oracle $i$: like previous oracle $i$, but uses the provided oracle on the $i$th call.

\begin{lstlisting}
(* same as Oi_prg but each GenUpdate in it has been converted to OracleComp *)
(* number of calls starts at 0 and ends at q. e.g.
G1:      RB  PRF PRF
Gi_rf 1: RB  RF  PRF (i = 1 here)
G2:      RB  RB  PRF *)
(* number of calls: first call is 0, last call is (numCalls - 1) for numCalls calls total
G0: PRF PRF PRF <-- Gi_prf 0
    RF  PRF PRF <-- Gi_rf 0
G1: RB  PRF PRF <-- Gi_prf 1
    RB  RF  PRF <-- Gi_rf 1
G2: RB  RB  PRF
    RB  RB  RF
G3: RB  RB  RB  <-- note that there is no oracle slot to replace here
    RB  RB  RB  <-- likewise
there should be (S numCalls) games, so games are numbered from 0 through numCalls *)
Definition Oi_oc' (i : nat) (sn : nat * KV) (n : nat) 
  : OracleComp Blist (Bvector eta) (list (Bvector eta) * (nat * KV)) :=
  [callsSoFar, state] <-2 sn;
  [k, v] <-2 state;
  let GenUpdate_choose := 
      if lt_dec callsSoFar i (* callsSoFar < i *)
      then GenUpdate_rb_intermediate_oc
      else if beq_nat callsSoFar i (* callsSoFar = i *)
           then GenUpdate_oc    (* uses provided oracle (PRF or RF) *)
      else if beq_nat callsSoFar O 
           then GenUpdate_noV_oc  (* first call does not update v *)
      else GenUpdate_PRF_oc in        (* uses PRF with (k,v) updating *)
  [bits, state'] <--$2 GenUpdate_choose (k, v) n;
  $ ret (bits, (S callsSoFar, state')).
  \end{lstlisting}

Replace PRF with random function.

Replace random function with random bits.

\subsection{List of lemmas}

From the top down (roughly breadth-first traversal of the proof tree).

For the top-level theorem, 
\begin{lstlisting}
G1_G2_close : | Pr[G1_prg] - Pr[G2_prg] | <= 
   (numCalls / 1) * Gi_Gi_plus_1_bound.
\end{lstlisting}
\begin{enumerate}
% @ not in code yet
\par
\item \begin{lstlisting}
GenUpdate_v_output_probability :
  Pr[G1_prg_original] == Pr[G1_prg].
  \end{lstlisting}
If we move each v-update to the beginning of the next $GenUpdate$ call, the games are equivalent, since the output the adversary sees is exactly the same. The rest of the proof will be done on the modified $GenUpdate$s.

\par
\item \begin{lstlisting}
G1_Gi_O_equal :
  Pr[G1_prg] == Pr[Gi_prg O].
\end{lstlisting}   

Recall that $G1$ is the first game we defined. It simulates "worst-case" real-world use of HMAC-DRBG by a non-adaptive adversary by calling $GenUpdate$ the maximum number of times, requesting the maximum number of blocks, and passing the output to the adversary. Since this is modeling real-world use, every call to $GenUpdate$ uses HMAC (abstracted to be any PRF). This game is equivalent to the first hybrid, where every call to the $GenUpdate\_oc$ oracle uses the PRF.

\par
\item \begin{lstlisting}
 G2_Gi_n_equal :
   Pr[G2_prg] == Pr[Gi_prg numCalls].
  \end{lstlisting}

Recall that $G2$ is the second game we defined. It simulates how we would ideally like HMAC-DRBG to behave. It calls $GenUpdate\_rb$ the maximum number of times, requesting the maximum number of blocks, and passing the output to the adversary. $GenUpdate\_rb$ is a version of $GenUpdate$ with every call to HMAC (the PRF) replaced by uniformly sampling a random bitvector. This game is equivalent to the last hybrid, where every call to the $GenUpdate\_oc$ oracle uses uniform random sampling.

\par 
\item \begin{lstlisting}
Gi_Gi_plus_1_close :
  forall (n : nat),
  | Pr[Gi_prg n] - Pr[Gi_prg (S n)] | <= Gi_Gi_plus_1_bound.
  \end{lstlisting}

This is the important part of the proof. We prove that the difference between each adjacent hybrid is bounded by some constant, defined as such:

\begin{lstlisting}
Gi_Gi_plus_1_bound := PRF_Advantage_i + Pr_collisions.
\end{lstlisting}

Adam's existing lemma handles the rest of the work, yielding the result that the difference between the first and the last hybrid is at most this bound times the number of hybrids.

\end{enumerate} 

%@ Moving v-updating: (proved) $GenUpdate\_v\_output\_probability$

For $Gi\_Gi\_plus\_1\_close$, number four above:
\begin{enumerate}
\par
\item \begin{lstlisting}
Gi_normal_prf_eq : forall (i : nat),
    Pr[Gi_prg i] == Pr[Gi_prf i].
    \end{lstlisting}
    
    We write the $i$th hybrid in terms of the $i$th oracle-replaced hybrid using the PRF oracle. Outputting random bits on calls $< i$ and the PRF afterward is equivalent to outputting random bits on calls $< i$, using the PRF oracle on call $i$, and using the PRF oracle afterward. 
    \begin{lstlisting}
   n = 4, i = 2
   call #   : 0   1   2   3
   Gi_prg 2: RB RB PRF PRF
   Gi_prf 2: RB RB PRF PRF
    \end{lstlisting}
    
    More formally,
    \begin{lstlisting}
    Theorem Gi_normal_prf_eq_compspec :
  forall (l : list nat) (i : nat) (k1 k2 v : Bvector eta),
   comp_spec
     (fun (x : list (list (Bvector eta)) * (nat * KV))
        (y : list (list (Bvector eta)) * (nat * KV) * unit) =>
      fst x = fst3 y)
     (oracleMap (pair_EqDec nat_EqDec eqDecState) (list_EqDec eqdbv)
        (Oi_prg i) (O, (k1, v)) l)
        
     ((oracleCompMap_inner
         (pair_EqDec (list_EqDec (list_EqDec eqdbv))
            (pair_EqDec nat_EqDec eqDecState))
         (list_EqDec (list_EqDec eqdbv)) (Oi_oc' i) 
         (O, (k2, v)) l) unit unit_EqDec (* note: k's differ. we aren't using this one *)
        (f_oracle f eqdbv k1) tt).
    \end{lstlisting}
    
    % TODO list l is not globally accurate
    This theorem is quantified over two important things: the list $l$ of blocks that the adversary requests per call, and the number of the hybrid $i$. Intuitively, given that the two computations (one using \li|oracleMap|, the other using \li|oracleCompMap_inner|) output equal pseudorandom bits for a list $l$, if we make another call, the two outputs for that call will be equal too. This is true because there are three cases, according to the structure of \li|Oi_oc'|. Let $n$ denote the length of $l$.
    \begin{enumerate}
    \item $n+1 > i$: for the new call, we use the PRF oracle in both computations.
    \item $n+1 = i$: for the new call, in the \li|oracleMap| computation, we use the PRF oracle, and in the \li|oracleCompMap_inner| computation, we use the provided oracle. The caller is providing \li|f_oracle|, which is the PRF oracle.
    \item $n +1 < i$: for the new call, we use the RB oracle in both computations.
    \end{enumerate}
    
    To prove this in Coq, we have to encode the insight that the theorem is inductive over \textbf{appending} to the list, rather than pre-pending (\li|cons|ing) to the beginning of the list. Thus, we induct on the reverse of the list $l$.
    
    We also have to deal with the special case of the first call, since we must use the special \li|GenUpdate_noV| oracle on that call. So we set $calls > 0$, perform the induction on the reverse of the list, then add the first call onto the head of the list.
    
\par
\item \begin{lstlisting}
Gi_prf_rf_close_i : forall (i : nat),
  | Pr[Gi_prf i] - Pr[Gi_rf i] | <= PRF_Advantage_Game i.
  \end{lstlisting}
  
	In the $i$th call to the $GenUpdate$ oracle, replace the pseudorandom function (PRF) oracle used with the random function (RF) oracle. 
	
      \begin{lstlisting}
   n = 4, i = 1
   call #   : 0   1   2   3
   Gi_prf 2: RB RB PRF PRF
   Gi_rf 2:   RB RB   RF PRF
    \end{lstlisting}
	
	The difference in probability that any adversary can distinguish between the PRF and the RF is defined by cryptographers to be upper-bounded by a quantity called \lstinline|PRF_Advantage|. We call this adversary \li|PRF_Adversary|.
	
\begin{lstlisting}
Definition PRF_Advantage_Game i : Rat := 
  PRF_Advantage RndK ({0,1}^eta) f eqdbl eqdbv (PRF_Adversary i).
  \end{lstlisting}
    	    
    \begin{lstlisting}
    PRF_Advantage = 
fun (D R Key : Set) (RndKey : Comp Key) 
  (RndR : Comp R) (f : Key -> D -> R) 
  (A : OracleComp D R bool) =>
| Pr[PRF_G_A RndKey f A] - Pr[PRF_G_B RndR A] |
\end{lstlisting}
	
	The PRF adversary is given an oracle (PRF or RF with equal probability) and can call it as many times as it wants on whatever inputs it chooses. It needs to guess whether the oracle was the PRF or the RF. 
  
We want to get our existing hybrid game $i$ in this format, so we simply construct this PRF adversary by passing the oracle we are given to the abstract PRG, then returning what our PRG adversary returns. 

\begin{lstlisting}
Definition PRF_Adversary (i : nat) : OracleComp Blist (Bvector eta) bool :=
  bits <--$ oracleCompMap_outer _ _ (Oi_oc' i) maxCallsAndBlocks;
  $ A bits.
\end{lstlisting}  

Using \li|PRF_Adversary| allows us to swap out the PRF for the random function, which is much easier to reason about, at the cost of adding \li|PRF_Advantage| to our final bound.

	It is a little questionable that this difference in probability (\lstinline|PRF_Advantage|) is defined to be the same upper bound no matter how many times the oracle in question is called within \li|GenUpdate| (and it is called $2 + numBlocks$ times, not just once). %@cite
  
\par
\item \begin{lstlisting}
 Gi_rf_rb_close : forall (i : nat),
  | Pr[Gi_rf i] - Pr[Gi_prg (S i)] | <= Pr_collisions.
  \end{lstlisting} % see comment above this thm for example
 
  We replace the random function oracle in the $i$th call with an oracle that simply outputs random bits. We want to upper-bound the difference in probability that any adversary can distinguish a list of $n$ things outputted by a random function (where each output is used as the next input) from a list of $n$ uniformly sampled random bitvectors. 
    
  \begin{lstlisting}
n = 4
Gi_rf  2:    RB  RB  RF PRF
Gi_prg 3:    RB  RB  RB PRF
\end{lstlisting}
  
  We show that it is the probability that there is a collision in the random function's inputs, which is a list of length $n$. Intuitively, the random function acts exactly like random bits, except for the pathological case where one of the randomly-sampled outputs $O$ happens to be one of the previous inputs. Then, when it is fed in as an input, $RF(O)$ yields its previous output, since it was "cached." In fact all outputs will repeat from then on, leading to a "cycle." 
  
  For example, take $101$ as a fixed initial input, and everything after it as an output. $*000*$ denotes the bad event of the first repeated input. Note the following cycle.
  
  $101, 000, 011, 001, \\
      *000*, *011*, *001*, \\
      *000*, *001*, \ldots$

  The analogous proof in \li|PRF_DRBG| is \li|PRF_DRBG_G3_G4_close|.
  
\end{enumerate}

For PRF Advantage (\lstinline|Gi_prf_rf_close|), number two above:

\begin{enumerate}
\par
\item 
\begin{lstlisting}
  Gi_prf_rf_close_i : forall (i : nat), 
  | Pr[Gi_prf i] - Pr[Gi_rf i] | <= PRF_Advantage_Game i. 
  \end{lstlisting}
    
  \begin{lstlisting}
  n = 4, i = 2
  Gi_prf 2: RB RB PRF PRF PRF
  Gi_rf 2:   RB RB RF   PRF PRF
  \end{lstlisting}
  
  The PRF advantage for hybrid game $i$ is defined to be the normal PRF advantage using the constructed PRF adversary on the $i$th game. Note that here the PRF advantage is parametrized by $i$, whereas in a non-hybrid argument, it would simply be the cryptographer-defined upper bound of \li|PRF_Advantage|.
 
 \begin{lstlisting}
Definition PRF_Advantage_Game i : Rat := 
  PRF_Advantage RndK ({0,1}^eta) f eqdbl eqdbv (PRF_Adversary i).
  \end{lstlisting}

   We can prove this theorem by simply unfolding the definitions of \li|Gi_prf| and \li|Gi_rf|, because they are both in the form stipulated by \li|PRF_Advantage|. The RF game passes the oracle to an adversary, which returns a guess.
   
\begin{lstlisting}
Definition Gi_rf (i : nat) : Comp bool :=
  [b, _] <-$2 PRF_Adversary i _ _ (randomFunc ({0,1}^eta) eqdbl) nil;
  ret b.
\end{lstlisting}  

The PRF game uniformly samples a random key for the adversary, then passes the adversary the PRF oracle using that key (which it cannot see).

\begin{lstlisting}
Definition Gi_prf (i : nat) : Comp bool :=
  k <-$ RndK;
  [b, _] <-$2 PRF_Adversary i _ _ (f_oracle f _ k) tt;
  ret b.
\end{lstlisting}  
  
  \par
\item 
\begin{lstlisting}
    PRF_Advantages_lt :  forall (i : nat), 
    PRF_Advantage_Game i <= PRF_Advantage_Game 0.
    \end{lstlisting}
    
    We would like to use a constant \li|PRF_Advantage| and eliminate the $i$, so we arbitrarily pick $i = 0$. 
    
  \begin{lstlisting}
  n = 4, i = 0
  Gi_prf 0: PRF PRF PRF PRF 
  Gi_rf 0:   RF   PRF PRF PRF 
  \end{lstlisting}
  
  The \li|PRF_Advantage|s are the same for all $i$ except $i=n$ (the number of calls to the \li|GenUpdate| oracle). For $i=n$, \li|PRF_Advantage n| = 0, since everything has been replaced with random bits, so the two hybrids are equal. Hence the $\leq$ in the theorem.
  
  \begin{lstlisting}
  n = 4, i = 4
  Gi_prf 4:  RB RB RB RB
  Gi_rf 4:    RB RB RB RB
  \end{lstlisting}  
    
\end{enumerate}

Identical until bad section. 
\\ \textbf{Note.} This section is outlined but the theorems are not explained as fully as in the previous section. I'll finish this in the thesis.
\\

\lstinline|Gi_rf_rb_close|, number three for \lstinline|Gi_Gi_plus_1_close| above:
\begin{enumerate}
\par
\item \begin{lstlisting}
Gi_normal_rb_eq : forall (i : nat),
    Pr[Gi_prg (S i)] == Pr[Gi_rb i].
    \end{lstlisting} 
    
Put \li|Gi_prg| into the form using the PRF adversary, passing it the RB oracle.

The idea here is much the same as \li|Gi_normal_prf_eq|.

\par
\item \begin{lstlisting} 
Gi_rf_return_bad_eq : forall (i : nat),
Pr[Gi_rf i] == Pr[x <-$ Gi_rf_bad i; ret fst x].
  \end{lstlisting}
  
  Expose the bad event in \li|Gi_rf|l. The bad event is that there are duplicates in the inputs to the $i$th oracle call.

\par
\item \begin{lstlisting}
Gi_rb_return_bad_eq : forall (i : nat),
    Pr[Gi_rb i] == Pr[x <-$ Gi_rb_bad i; ret fst x].
\end{lstlisting}

Expose the bad event \li|Gi_rb|.

\par
\item \begin{lstlisting}
Gi_rb_rf_identical_until_bad : forall (i:nat), 
| Pr[x <-$ Gi_rf_bad i; ret fst x] 
  - Pr[x <-$ Gi_rb_bad i; ret fst x] | 
<= Pr[x <-$ Gi_rb_bad i; ret snd x]
\end{lstlisting}                                

The difference of two games is difficult to work with. We prefer to work with one game, which we can then massage and prove equivalent to other games. Therefore, we apply Bellare's "fundamental lemma of game-playing." It upper-bounds the probability that the adversary can distinguish between \li|Gi_rf_bad| and \li|Gi_rb_bad| by the probability that the bad event occurs in \li|Gi_rb_bad|, which gives us a single game to work with.

% @ talk about what the bad event is.
                                              
\par
\item \begin{lstlisting}
Gi_rb_bad_collisions : forall (i : nat),
Pr  [x <-$ Gi_rb_bad i; ret snd x ] <= 
   Pr_collisions.
\end{lstlisting}

As explained in \li|Gi_rf_rb_close| above, the probability of a bad event happening in the RB game is bounded by the probability of collisions in a list of length (n+1) of randomly-sampled bit vectors. 

To prove this, after transforming and simplifying \li|Gi_rb_bad| via many intermediate games, we apply the collision bound found in \li|PRF_DRBG|.

\end{enumerate} 

To prove \lstinline|Gi_rb_rf_identical_until_bad| (number two above):

\begin{enumerate}
\par
\item \begin{lstlisting}
fundamental_lemma_h : forall (A : Set) 
   (eqda : EqDec A) (c1 c2 : Comp (A * bool)),
   
   Pr  [x <-$ c1; ret snd x ] == 
   Pr  [x <-$ c2; ret snd x ] ->
   
   (forall a : A, evalDist c1 (a, false) == 
                      evalDist c2 (a, false)) ->
                      
   forall a : A,
   | evalDist (x <-$ c1; ret fst x) a - 
     evalDist (x <-$ c2; ret fst x) a |
      <= Pr  [x <-$ c1; ret snd x ].
\end{lstlisting}

This is the statement of Bellare's fundamental lemma. Below, we prove the two assumptions in the theorem, yielding the conclusion.

\par
\item \begin{lstlisting}
 Gi_rb_rf_return_bad_same :  forall (i : nat),
    Pr  [x <-$ Gi_rb_bad i; ret snd x ] ==
    Pr  [x <-$ Gi_rf_bad i; ret snd x ].
\end{lstlisting}

This is the first assumption needed to apply the fundamental lemma: show that the two games have the same probability of returning bad (that is, the bad event has the same probability of happening).

Concretely, this is true for \li|Gi_rb_bad| and \li|Gi_rf_bad| because the probability of the bad event in both is the probability of duplicates in a list of length $n$ of uniformly-randomly-sampled bit vectors.

\par
\item \begin{lstlisting}
 Gi_rb_rf_no_bad_same : forall (i : nat) (a : bool),
   evalDist (Gi_rb_bad i) (a, false) == 
   evalDist (Gi_rf_bad i) (a, false).
\end{lstlisting}

I don't work with it probabilistically; working in the program logic (TODO explain what this means), the goal becomes this:

\begin{lstlisting}
   comp_spec (fun b1 b2 : bool * bool => b1 = (a, false) <-> b2 = (a, false))
     (Gi_rb_bad i) (Gi_rf_dups_bad i)
\end{lstlisting}     

This is the second assumption needed to apply the fundamental lemma: given that the bad event does not happen, the distributions of the outputs of the two games are identical (that is, "identical until bad").

Concretely, this is true for \li|Gi_rb_bad| and \li|Gi_rf_bad| because if there are no duplicates in the $i$th oracle call's inputs, clearly the random function behaves exactly like uniformly sampling random bitvectors. So their output should be indistinguishable (or identical, if you provide each run with the same "coins" of randomness).

\end{enumerate}

%%%% 4/12/17

% TODO this is definitely *not* a high-level overview

% TODO write out what they mean
Both \li|Gi_rb_rf_return_bad_same| and \li|Gi_rb_rf_no_bad_same|, when unfolded, essentially assert that some combined postcondition relates the \li|PRF_Adversary| executions, one using the random bits oracle and one using the random function that preserves duplicate.

\li|Gi_rb_rf_return_bad_same|, when unfolded, looks like this:

\begin{lstlisting}
   comp_spec eq
     (a <-$
      (PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv)) rb_oracle nil;
      x <-$ ([b, state]<-2 a; ret (b, hasInputDups state)); ret snd x)
     (a <-$
      (PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv)) randomFunc_withDups nil;
      x <-$ ([b, state]<-2 a; ret (b, hasInputDups state)); ret snd x)
\end{lstlisting}      

The postcondition here is equality (\li|comp_spec eq|). That is, both computations return the same value for whether the bad event happened.

And \li|Gi_rb_rf_no_bad_same|, when unfolded, looks like this:

\begin{lstlisting}
   comp_spec (fun b1 b2 : bool * bool => b1 = (a, false) <-> b2 = (a, false))
     (z <-$
      (PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv)) rb_oracle nil;
      [b, state]<-2 z; ret (b, hasInputDups state))
     (z <-$
      (PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv)) randomFunc_withDups nil;
      [b, state]<-2 z; ret (b, hasInputDups state))
\end{lstlisting}      

The postcondition here is that if \li|hasInputDups state = false| (that is, the bad event didn't happen), then both computations return the same output bits (the \li|a| in \li|b1 = (a, false) <-> b2 = (a, false)|).

So, the combined postcondition on the \li|PRF_Adversary| computation (which returns the bits and state) simply combines the two postconditions above. Stated as a separate lemma,

\begin{lstlisting}
Theorem PRF_Adv_eq_until_bad : forall (i : nat),
   comp_spec 
     (fun a b : bool * list (Blist * Bvector eta) =>
        let (adv_rb, state_rb) := a in
        let (adv_rf, state_rf) := b in
        let (inputs_rb, outputs_rb) := (fst (split state_rb), snd (split state_rb)) in
        let (inputs_rf, output_rf) := (fst (split state_rf), snd (split state_rf)) in
        hasDups _ inputs_rb = hasDups _ inputs_rf /\
        (hasDups _ inputs_rb = false ->
         state_rb = state_rf /\ adv_rb = adv_rf))
         
     ((PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv)) rb_oracle nil)
        
     ((PRF_Adversary i) (list (Blist * Bvector eta))
        (list_EqDec (pair_EqDec eqdbl eqdbv))
        randomFunc_withDups nil).
\end{lstlisting}
% true -- if there are no duplicates, then the random function behaves exactly like RB, so the key is randomly sampled AND the v (going into the PRF) is also randomly sampled. so the outputs should be the same. in fact, if there are no dups, PRF_Adv rf i = PRF_Adv rb i.

% TODO intuition, write out what the computation is
The postcondition looks intimidating, but is simply the conjunction of the two postconditions discussed above. A computation has duplicates in the oracle inputs only if the other computation does. And, if there are no duplicates, then the oracle states are equal and the adversary guesses are equal. I use that lemma to prove both the identical until bad conditions, and now we only have to worry about proving the one lemma \li|PRF_Adv_eq_until_bad|.

% TODO explain oraclecompmap_inner / outer
\li|PRF_Adversary| generates the pseudorandom bits, then returns the indistinguishability adversary's guess. 

\begin{lstlisting}
Definition PRF_Adversary (i : nat) : OracleComp Blist (Bvector eta) bool :=
  bits <--$ oracleCompMap_outer _ _ (Oi_oc' i) maxCallsAndBlocks;
  $ A bits.
\end{lstlisting}

So, we can push the postconditions into the generation of the pseudorandom bits, specifically into $oracleCompMap_inner$, and use that to prove \li|PRF_Adv_eq_until_bad|. The inner lemma is:

\begin{lstlisting}
Theorem oracleCompMap__oracle_eq_until_bad_dups : forall (i : nat) b b0,
    comp_spec
     (fun y1 y2 : list (list (Bvector eta)) * list (Blist * Bvector eta) =>
        hasDups _ (fst (split (snd y1))) = hasDups _ (fst (split (snd y2))) /\
        (hasDups _ (fst (split (snd y1))) = false ->
         snd y1 = snd y2 /\ fst y1 = fst y2))

     ((z <--$
       oracleCompMap_inner
         (pair_EqDec (list_EqDec (list_EqDec eqdbv))
            (pair_EqDec nat_EqDec eqDecState))
         (list_EqDec (list_EqDec eqdbv)) (Oi_oc' i) 
         (O, (b, b0)) maxCallsAndBlocks; [bits, _]<-2 z; $ ret bits)
        (list (Blist * Bvector eta)) (list_EqDec (pair_EqDec eqdbl eqdbv))
        rb_oracle nil)
         
     ((z <--$
       oracleCompMap_inner
         (pair_EqDec (list_EqDec (list_EqDec eqdbv))
            (pair_EqDec nat_EqDec eqDecState))
         (list_EqDec (list_EqDec eqdbv)) (Oi_oc' i) 
         (O, (b, b0)) maxCallsAndBlocks; [bits, _]<-2 z; $ ret bits)
        (list (Blist * Bvector eta)) (list_EqDec (pair_EqDec eqdbl eqdbv))
        randomFunc_withDups nil).
\end{lstlisting}        

% TODO tape of randomness 
The postcondition is the same as in \li|PRF_Adv_eq_until_bad|, except that instead of saying that the adversary guesses are the same, we say that the generated pseudorandom bits are the same, which clearly implies the former. (Intuitively, doing proofs relating two probabilistic programs is like proving things about the deterministic programs given the same "tape" of randomness.) 

The proverbial buck stops here; we don't push the postcondition back further into \li|oracleCompMap_inner| (which iterates chosen \li|GenUpdate| oracles), \li|Oi_oc| (which chooses which \li|GenUpdate| oracle to use), the \li|GenUpdate| oracles, or \li|Gen_loop|, which uses the provided random bits or random-function-with-duplicates oracle to generate bits. If we did that, we would have to reason about many computations extraneous to the oracle, whereas we only need to reason about the properties of the oracle and how it handles bad events.

% TODO too many uses of "reason"
We use a powerful theorem called \li|fcf_oracle_eq_until_bad| to "strip away" the computations that use the oracle so we can just reason about the oracle. Informally, \li|fcf_oracle_eq_until_bad| states that postconditions in our "identical until bad" form are true if we can prove three side conditions:

% TODO paste in the code for the side conditions and id-until-bad side condition
\begin{enumerate}
\item If the two oracles start in the same state, if the bad event either did not happen or did happen in both states (meaning NOT (the bad event happened in one state and not the other)), then the same identical-until-bad postcondition relates one run of the each of the oracles.

\item For the first oracle, if its state starts bad, it stays bad.

\item For the second oracle, if its state starts bad, it stays bad.

\end{enumerate}

This identical until bad postcondition is (TODO write out). The full statement of the theorem is very long, so it is included in the appendix. The proof, done by Petcher (2015), is also included in the appendix. % TODO

% TODO appendix

Because this proof doesn't depend on the details of the computations, only the oracle, and our oracles here are the same as in the corresponding proof in \li|PRF_DRBG| (which is \li|PRF_A_randomFunc_eq_until_bad|), so we can simply re-use that proof to prove \li|oracleCompMap__oracle_eq_until_bad_dups|.

Here's how we prove the side conditions. (Numbers correspond to above numbering.) 

\begin{enumerate}
\item To prove the first condition: first, we unfold the definition of \li|randomFunc_withDups| in the statement of the theorem.

\begin{lstlisting}
y <-$
      match arrayLookup D_EqDec xs a with
      | Some y => ret y
      | None => { 0 , 1 }^eta
      end; ret (y, (a, y) :: xs)
\end{lstlisting}      

Then we do a case analysis on whether the newest input is a duplicate (that is, is already in the state of the random function oracle that preserves duplicates). In the Coq tactic language, that's \li|case_eq (arrayLookup _ xs a)|.

	The first case is easy. If the element \li|a| is \textbf{not} in the random function's state \li|xs|, then the random function uniformly randomly samples a bitvector, so the expression simplifies to be identical to that of \li|rb_oracle|:
	
	\begin{lstlisting}
	   comp_spec
     (fun y1 y2 : Bvector eta * list (D * Bvector eta) =>
      hasDups D_EqDec (fst (split (snd y1))) =
      hasDups D_EqDec (fst (split (snd y2))) /\
      (hasDups D_EqDec (fst (split (snd y1))) = false ->
       snd y1 = snd y2 /\ fst y1 = fst y2))
     (y <-$ { 0 , 1 }^eta; ret (y, (a, y) :: x2))
     (r <-$ { 0 , 1 }^eta; ret (r, (a, r) :: x2))
     \end{lstlisting}
     
     We were already given the first postcondition as a hypothesis. The second postcondition holds because indeed, there are no duplicates (by the case analysis) and the return values are equal.

	The second case is more involved. If the element \li|a| \textbf{is} in the random function's state \li|xs|, then we know there are duplicates in the random function's state. So, since the two oracles start with the same state, the \li|rb_oracle| also has duplicates in its state. After simplifying, our new goal is to prove this:
	
	\begin{lstlisting}
	  comp_spec
     (fun y1 y2 : Bvector eta * list (D * Bvector eta) =>
      hasDups D_EqDec (fst (split (snd y1))) =
      hasDups D_EqDec (fst (split (snd y2))) /\
      (hasDups D_EqDec (fst (split (snd y1))) = false ->
       snd y1 = snd y2 /\ fst y1 = fst y2)) (ret (b, (a, b) :: x2))
     (ret (b0, (a, b0) :: x2))
     \end{lstlisting}
	
	% TODO it's not clear what the hypotheses are in the context
	% TODO how to explain coq proofs in a paper?? Maybe do a 2-column Coq-dev on the left, explanation on the right (with various states and hypotheses changing?)
	
	So, we use the tactic \li|fcf_spec_ret|, which says, "we're done manipulating the two games and now they simply return things; let's prove that the postcondition relates their two return values."
	
	The second part of the postcondition is easy to discharge: 
	\begin{lstlisting}
	(hasDups D_EqDec (fst (split (snd y1))) = false ->
       snd y1 = snd y2 /\ fst y1 = fst y2)
       \end{lstlisting}
       It starts with the assumption that there are no duplicates in the entire state. But, by our case analysis earlier, we are in the case where there are duplicates in the tail of the state, which implies that there are duplicates in the entire state. So, we can eliminate this case.
       
       The first part of the postcondition,
       
       % TODO write out these postconditions properly
       \begin{lstlisting}
       hasDups D_EqDec (fst (split (snd y1))) =
      hasDups D_EqDec (fst (split (snd y2)))
      \end{lstlisting}
      
      requires us to prove that whether the \li|randomFunc_withDups| oracle has duplicates equals whether the \li|rb_oracle| has dups. This follows because they started with the same initial state, which has duplicates.
       \li|hasDups (thing1 :: x2) = hasDups (thing2 :: x2)| since \li|hasDups x2|
	
\item For the \li|randomFunc_withDups| oracle, the state is append-only. So, if the state starts out with duplicates, no matter what we query or what we return, the state will continue to have duplicates. 

\item For the \li|rb_oracle|, the state is also append-only. So, as above, if the state starts out with duplicates, no matter what we query or what we return, the state will continue to have duplicates. 

\end{enumerate}

The commented Coq proof of this can be found in the appendix.

\subsection{Proof graph}

To add, after I break up \li| Gi_rb_rf_no_bad_same|. I've already made one using \li|coq-dpdgraph|.

\subsection{Current limitations of the formal proof}

We abstracted or ignored a few parts of HMAC-DRBG.

\begin{itemize}
%@write this out
\item NIST specifies that $Instantiate$ produces the \kv  by calling $Update$ using hardcoded constant \kv and some additional entropy. The entropy might not be uniformly random, so to reason about this construction, we would have to show that HMAC is an "entropy extractor." This seems not worth the trouble, so we assume that $Instantiate$ samples \kv uniformly at random.
\item $Update$ includes a call to $Reseed$ if the reseed counter is greater than reseed count, or the DRBG's state is compromised. ($Reseed$ provides prediction resistance by injecting entropy unknown to the adversary into the DRBG). We remove the call to $Reseed$ because again, it's hard to reason about entropy, so our DRBG is not prediction resistant. Also, reseed count is a very large number that means you would naturally reseed about once every million years.
\item We need to figure out how to adapt the indistinguishability proof to a nonadaptive adversary that picks any list of $blocksPerCall$ and $numCalls$ beforehand, not the hardcoded $maxBlocksPerCall$ and $maxCalls$. One can imagine a pathological DRBG that outputs its key for only $numCalls = 7$, for example.
\item We need to figure out how to adapt the indistinguishability proof to an adaptive adversary. This adversary can choose the number of calls and number of blocks per call, then once it receives output, can call again as many times as it wishes with parameters of its choice. One can imagine a pathological DRBG that "encourages" an adversary to input $7$ as $blocksPerCall$ and outputs its secret key after 3 such calls, so that if it discovers that $7$ is a "bad" input, it keeps inputting it. A non-adaptive adversary would have negligible chance of making this experiment or this discovery.
\item We ignore the "additional input" and "personalization string" parameters of $Generate$, $Update$, and $Instantiate$. These are generally used for fork-safety. If you fork the DRBG process, the child process starts with exactly the same internal state, so one would update the state with something unique to that process, generally the process ID.
\item Entropy failure
\end{itemize}

\subsection{Comparison to existing proof of HMAC-DRBG security}

To write after I've read the Hirose paper. %@cite

\begin{itemize}
\item How does it compare to our paper proof? Our computer proof?
\item Why is formalizing our proof so much work? (Number of hours and lines of code?)
\end{itemize}

\subsection{Comments on HMAC-DRBG's design}

Formally verifying HMAC-DRBG helped us notice several NIST design decisions that made our job either harder or easier.

\begin{itemize}
\item NIST re-keys the PRF with a length-extended input. This is good because HMAC can take inputs of any length, and all previous inputs for HMAC with that key were of fixed length (since HMAC has a fixed output). So we know the new key won't collide with previous outputs.
\item Updating the v immediately after re-keying the PRF, in the same oracle call, is hard to reason about. This is because at the beginning of each call, by the hybrid argument, we can assume that the \kv have been randomly sampled. Now we have to replace the key with a random key to reason about updating the v. The solution is simple: we move each v-update to the beginning of the next call and prove that the new sequence of programs is indistinguishable to the adversary. (TODO explain this with pictures)
\item In $Update$, NIST does (++ [v]) instead of (v ::). The former is intuitive on paper; the latter is much easier to reason about by induction in Coq.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Additional properties to prove about HMAC-DRBG}

We plan to prove that HMAC-DRBG possesses backtracking resistance. That is, if it is compromised at time $T$, the adversary still cannot distinguish HMAC-DRBG previous output from ideal random strings. That is, if the adversary is given a $Compromise$ oracle that it can call after a certain number of calls to the $GenUpdate$ oracle to reveal the PRG's internal $(K,V)$, the adversary still cannot distinguish the previous output from ideal random strings. We plan to do this proof and reuse much of our existing work on indistinguishability. We're working on formalizing the definitions and working out some issues regarding v-updating and nonadaptive vs. adaptive adversaries.

% how does this work?
%@ the v-updating

%@cite
NIST also specifies that HMAC-DRBG possesses the complementary property of prediction resistance. That is, if it is compromised at time $T$, the adversary will find it difficult to distinguish HMAC-DRBG's future output from ideal random strings. Naively, if given $(K, V)$ at time $T$, the adversary should be able to compute all future DRBG output and thus distinguish. Thus, the $Reseed$ function is supposed to ensure prediction resistance by injecting fresh entropy into the DRBG that is unknown to the adversary. (It refreshes the $(K,V)$ by re-HMACing them with some entropy appended to the previous $(K,V)$)

However, proving things about this is difficult. Dodis et al. (2013) proved that the Linux PRNG was insecure and did not possess prediction resistance. However, they had to do tricky reasoning about how much entropy was injected at once and where. They had to reason about, for example, the difference between injecting entropy as five bits per call over ten calls, versus fifty bits in one call, and relative difficulties for the adversary.

%@cite

\section{Linking our crypto spec with the functional spec}

Naphat Sanguansin '16 proved functional correctness of the mbed TLS implementation of HMAC-DRBG using a different functional specification, also written in Gallina. To create a truly end-to-end proof of correctness, we must prove that our cryptographic specification of HMAC-DRBG is the same as his specification. 

\subsection{Proving functional correctness of HMAC-DRBG}

To add: VST overview. Hoare logic overview. Summary of Naphat's proof. A diagram of the whole project, similar to the HMAC diagram. My prior work for HMAC.
%@

\subsection{Bridging the gaps between the specifications}

We must prove lemmas about at least the following differences between the specifications.

\begin{enumerate}
\item Naphat's code has essentially the same core loop ($Gen_loop$) and $Generate$ and $Update$ code. However, it's surrounded by many layers of error checking code, e.g. for \li|prediction_resistance_request|. We need to prove equivalence modulo error checking.
\item Naphat's code also models failures in the type for the entropy stream. It is an infinite stream of either bit or failure. Also, it is not necessarily ideal randomness. We need to relate FCF's sampling uniformly at random to this more realistic entropy model. Adam Petcher's thesis provides some theorems about the operational semantics of FCF that can help us with this.
\end{enumerate}

\section{Plan for the next two months}

There are 21 admitted lemmas left to prove that I'm confident about, and 1 lemma left that I'm sure is true, but am not sure how to prove. I planned to have proved them by the beginning of March. However, since it is now the beginning of March, and I'm traveling for 1.5 weeks for graduate school visits, it is plausible that I can have the indistinguishability proof all proven by the end of March.

Matt and I have started working on the backtracking resistance proof. It relies heavily on reusing our work on the indistinguishability proof, modulo adaptiveness of adversary. So, we will concurrently work on writing an informal proof of that and formalizing the specifications and definitions in FCF. I will likely not do the formal proofs until April or July, but there shouldn't be too many, given that we are reusing the indistinguishability proofs.

Also, we need to figure out how to possibly adapt the indistinguishability proof to a nonadaptive adversary that picks any list of $blocksPerCall$ and $numCalls$ beforehand, not the hardcoded $maxBlocksPerCall$ and $maxCalls$.

I plan to start writing my thesis in the beginning of April and finish a draft by the end of the third week of April, then revise it. In April I'll look more into doing the spec equivalence proof, but probably not do it. I plan to do this proof in hopefully less than one month during July. 

\section{Future work}

HMAC is slow. AES is fast. Thus, AES CTR-DRBG, which uses AES in CTR mode, is much more widely used in practice than HMAC-DRBG (e.g. Amazon uses AES CTR-DRBG). It would be practically useful to formally verify HMAC-DRBG, but also theoretically interesting. How do our proofs generalize? (Some things would be different; e.g. HMAC is assumed a PRF, and AES is assumed a pseudo-random permutation. Their respective DRBGs are slightly different as well. Some things would break; e.g. to refresh the key without a collision, NIST cannot length-extend the input.) Can we build a general framework for verifying DRBGs? How automated can it be? Is the concrete security bound better?

Also, OpenSSL's team is picking or designing a new PRNG--we hope our work encourages implementors to co-design with formal methods researchers.

\section{Conclusion}

To add.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{acknowledgments}

I'd like to thank Adam Petcher, Matt Green, Andrew Appel, Lennart Beringer, and Naphat Sanguansin for their help.

\end{acknowledgments}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{References}

\bibliographystyle{plainnat}

\begin{thebibliography}{99}

%\bibitem{byrd2009}
%Byrd, William E. \emph{Relational programming in minikanren: Techniques, applications, and implementations.} Diss. faculty of the University Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the Department of Computer Science, Indiana University, 2009.

\bibitem{affeldt2009}
Affeldt, Reynald, David Nowak, and Kiyoshi Yamada. "Certifying assembly with formal cryptographic proofs: the case of BBS." \emph{Electronic Communications of the EASST} 23 (2009).

\bibitem{appel2015}
Appel, Andrew W. "Verification of a cryptographic primitive: SHA-256." \emph{ACM Transactions on Programming Languages and Systems (TOPLAS)} 37, no. 2 (2015): 7.

\bibitem{barker2012}
Barker, Elaine, and John Kelsey. "NIST Special Publication 800-90A: Recommendation for random number generation using deterministic random bit generators." (2012).

\bibitem{barthe2011}
Barthe, Gilles, Benjamin Grégoire, Sylvain Heraud, and Santiago Zanella Béguelin. "Computer-aided security proofs for the working cryptographer." In \emph{Advances in Cryptology–CRYPTO} 2011, pp. 71-90. Springer Berlin Heidelberg, 2011.

\bibitem{bellare2004}
Bellare, Mihir, and Phillip Rogaway. "Code-Based Game-Playing Proofs and the Security of Triple Encryption." \emph{IACR Cryptology ePrint Archive} 2004 (2004): 331.

\bibitem{beringer2015}
Beringer, Lennart, Adam Petcher, Katherine Q. Ye, and Andrew W. Appel. "Verified correctness and security of OpenSSL HMAC." In \emph{24th USENIX Security Symposium (USENIX Security 15)}, pp. 207-221. 2015.

\bibitem{campagna2006}
Campagna, Matthew J. "Security Bounds for the NIST Codebook-based Deterministic Random Bit Generator." \emph{IACR Cryptology ePrint Archive 2006} (2006): 379.

\bibitem{dodis2013}
Dodis, Yevgeniy, David Pointcheval, Sylvain Ruhault, Damien Vergniaud, and Daniel Wichs. "Security analysis of pseudo-random number generators with input:/dev/random is not robust." In \emph{Proceedings of the 2013 ACM SIGSAC conference on Computer and Communications Security}, pp. 647-658. ACM, 2013.

\bibitem{dorre2015}
Dörre, Felix, and Vladimir Klebanov. "Pseudo-Random Number Generator Verification: A Case Study." \emph{Proceedings, Verified Software: Theories, Tools, and Experiments (VSTTE)} (2015).

\bibitem{hirose2008}
Hirose, Shoichi. "Security analysis of DRBG using HMAC in NIST SP 800-90." In \emph{Information Security Applications}, pp. 278-291. Springer Berlin Heidelberg, 2008.

\bibitem{petcher2015}
Petcher, Adam, and Greg Morrisett. "The foundational cryptography framework." \emph{In Principles of Security and Trust}, pp. 53-72. Springer Berlin Heidelberg, 2015.

\bibitem{sanguansin2016}
Sanguansin, Naphat. "Verification of a Deterministic Random Bits Generator." Independent work paper, Princeton University. 2016.
\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \appendix

\section{Definitions and proofs}

Will add worked examples of Coq proofs using FCF tactics.

 \end{document}





























%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
